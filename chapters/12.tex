\chapter{Epilogue}

In this book, I have focused on corpus linguistics as a methodology, more precisely, as an application of a general observational scientific procedure to large samples of linguistic usage. I have refrained from placing this method in a particular theoretical framework for two reasons.

The first reason is that I'm not convinced that linguistics should be focusing quite as much on theoretical frameworks, but rather on linguistic description based on data. Edward Sapir famously said that ``unfortunately, or luckily no language is tyrannically consistent. All grammars leak'' \citep[39]{sapir_language:_1921}. This is all the more true of formal models, that attempt to achieve tyrannical consistency by pretending those leaks do not exist or, if they do exist, are someone else's problem. To me, and to many others whose studies I discussed in this book, the ways grammars leak are simply more interesting than the formalisms that help us ignore this.

The second reason is that I believe that corpus linguistics has a place in any theoretical linguistic framework, as long as that framework has some commitment to modeling linguistic reality. Obviously, the precise place, or rather, the distance from the data analyzed using this method and the consequences of this analysis for the model depend on the type of linguistic reality that is being modeled. If it is language use, as, for example, in historically or sociolinguistically oriented studies, the distance is relatively short, requiring the researcher to discover the systematicity behind the usage patterns observed in the data. If it is the mental representation of language, the length of the distance depends on your assumptions about those representations.

Traditionally, those representations have been argued to be something fundamentally different from linguistic usage -- that they are an ephemeral ``competence'' based on a ``universal'' grammar that may be a ``mental organ'' \citep{chomsky_rules_1980} or an evolved biological instinct \citep{pinker_language_1994}, but that is dependent on and responsible for linguistic usage only in the most indirect ways imaginable. As I have argued in Chapters \ref{ch:needforcorpus} and \ref{ch:corpuslinguistics}, even those frameworks have no alternative to corpus data that does not suffer from the same drawbacks, without offering any of the advantages.

However, more recent models do not draw as strict a line between usage and mental representations. The ``Usage-Based Model'' \citep{langacker_concept_1991} is a model of linguistic knowledge based on the assumption that speakers initially learn language as a set of unanalyzed chunks of various sizes (``established units''), from which they derive linguistic representations of varying degrees of abstractness and complexity based on formal and semantic correspondences across these units \citet[cf.][266f]{langacker_concept_1991}. Hopper's ``Emergent Grammar'' is based on similar assumptions but is skeptical even of abstractness, viewing language, instead, as ``built up out of combinations of ... prefabricated parts. Language is, in other words, to be viewed as a kind of pastiche, pasted together in an improvised way out of ready-made elements'' \citep[144]{hopper_emergent_1987}.

In these models, the corpus becomes more than just a research tool, it becomes part of a model of linguistic competence itself \citep[cf.][]{brdar_cognitive_2011}. In fact, in the most radical version, the notion of ``lexical priming'' developed in \citet{hoey_lexical_2005}, the corpus essentially \textit{is} the model of linguistic competence:

\begin{quotation}
The notion of priming as here outlined assumes that the mind has a mental concordance of every word it has encountered, a concordance that has been richly glossed for social, physical, discoursal, generic and interpersonal context. This mental concordance is accessible and can be processed in much the same way that a computer concordance is, so that all kinds of patterns, including collocational patterns, are available for use. It simultaneously serves as a part, at least, of our knowledge base. \citep[11]{hoey_lexical_2005}
\end{quotation}

Obviously, this mental concordance would not correspond exactly to any concordance derived form an actual linguistic corpus. First, because -- as discussed in Chapters \ref{ch:needforcorpus} and \ref{ch:corpuslinguistics} -- no linguistic corpus captures the linguistic experience of a given individual speaker or the ``average'' speaker in a speech community; second, because the concordance that Hoey envisions is not a concordance of linguistic forms, but of contextualized linguistic \textit{signs} -- i.e., it contains all the semantic and pragmatic information that corpus linguists have to reconstruct laboriously in their analyses. Still, an appropriately annotated concordance from a balanced corpus would be a reasonable operationalization of this mental concordance \citep[cf. also][]{taylor_mental_2012}.

In less radical usage-based models of language, such as Langacker's, the corpus is not a model of linguistic competence, which is seen as a consequence of linguistic input perceived and organized by human minds with a particular structure (for example, the capacity for figure-ground categorization). It is, however, a reasonable model (or at least an operationalization) of this input. Many of the properties of language that guide the storage of units and the abstraction of schemas over these stored units can be derived from corpora (frequencies, associations between units of linguistic structure, distributions of these units across grammatical and textual contexts, the internal variability of these units, etc., cf \citet{stefanowitsch_corpus-based_2016} for discussion).

This view is explicitly taken in language acquisition research conducted within the Usage-Based Model (e.g. \citealt{tomasello_constructing_2003}, \citealt{dabrowska_formula_2001}, \citealt{diessel_acquisition_2004}), where children's expanding grammatical abilities (as reflected in acquisition corpora) are investigated against the input that they get from their caretakers. It is not always shared by the major theoretical proponents of the Usage-Based Model, who connect the notion of usage to the notion of linguistic corpora only in theory. However, it is a view that offers a tremendous potential to bring together two broad strands of research -- cognitive-functional linguistics (including some versions of construction grammar) and corpus linguistics (including attempts to build theoretical models on corpus data, such as Pattern Grammar \citep{hunston_pattern_2000} and Lexical Priming \citet{hoey_lexical_2005}). These strands have developed more or less independently and their proponents are sometimes mildly hostile toward each other over minor, but fundamental differences in perspective (see \citet{mcenery_corpus_2012}, Section 8.3 for discussion), but they could complement each other in many ways, cognitive linguistics providing a more explicitly psychological framework than most corpus linguists adopt, and corpus linguistics providing a methodology that cognitive linguists serious about usage urgently need.

Finally, in such usage-based models, as in models of language in general, corpora can also be seen as models (or operationalizations) of the typical linguistic output of the members of a speech community, i.e. the language produced based on their internalized linguistic knowledge. This is the least controversial view, and the one that I have essentially adopted throughout this book. Even under this view, corpus data remain one of the best sources of linguistic data we have, one that can only keep growing, providing us with ever deeper insights into the leaky, intricate, ever-changing signature activity of our species.

I hope this book has inspired you and I hope it will help you produce research that inspires all of us.